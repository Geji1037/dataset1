{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 150,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 0.756537914276123,
      "learning_rate": 0.000298,
      "loss": 1.9112,
      "step": 1
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8712475299835205,
      "learning_rate": 0.000296,
      "loss": 1.7295,
      "step": 2
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7904536128044128,
      "learning_rate": 0.000294,
      "loss": 1.8849,
      "step": 3
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9138381481170654,
      "learning_rate": 0.000292,
      "loss": 2.0524,
      "step": 4
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8656591176986694,
      "learning_rate": 0.00029,
      "loss": 1.7356,
      "step": 5
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9164708256721497,
      "learning_rate": 0.00028799999999999995,
      "loss": 1.5194,
      "step": 6
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.178040623664856,
      "learning_rate": 0.00028599999999999996,
      "loss": 1.5234,
      "step": 7
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.6008946895599365,
      "learning_rate": 0.00028399999999999996,
      "loss": 1.7181,
      "step": 8
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.16560959815979,
      "learning_rate": 0.00028199999999999997,
      "loss": 1.6592,
      "step": 9
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1796728372573853,
      "learning_rate": 0.00028,
      "loss": 1.6778,
      "step": 10
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8925339579582214,
      "learning_rate": 0.000278,
      "loss": 1.5256,
      "step": 11
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.0343574285507202,
      "learning_rate": 0.000276,
      "loss": 1.5641,
      "step": 12
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.0046840906143188,
      "learning_rate": 0.000274,
      "loss": 1.5347,
      "step": 13
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.167528748512268,
      "learning_rate": 0.00027199999999999994,
      "loss": 1.6503,
      "step": 14
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.4578863382339478,
      "learning_rate": 0.00027,
      "loss": 1.8034,
      "step": 15
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.054236888885498,
      "learning_rate": 0.00026799999999999995,
      "loss": 1.8098,
      "step": 16
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.3920259475708008,
      "learning_rate": 0.000266,
      "loss": 1.6982,
      "step": 17
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.1340948343276978,
      "learning_rate": 0.00026399999999999997,
      "loss": 1.7169,
      "step": 18
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9656311273574829,
      "learning_rate": 0.00026199999999999997,
      "loss": 1.6146,
      "step": 19
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.15850031375885,
      "learning_rate": 0.00026,
      "loss": 1.5378,
      "step": 20
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2135305404663086,
      "learning_rate": 0.000258,
      "loss": 1.6319,
      "step": 21
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.0498651266098022,
      "learning_rate": 0.000256,
      "loss": 1.5372,
      "step": 22
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1043049097061157,
      "learning_rate": 0.000254,
      "loss": 1.682,
      "step": 23
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.4530490636825562,
      "learning_rate": 0.00025199999999999995,
      "loss": 1.5554,
      "step": 24
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.1117125749588013,
      "learning_rate": 0.00025,
      "loss": 1.6938,
      "step": 25
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.5794919729232788,
      "learning_rate": 0.00024799999999999996,
      "loss": 1.7021,
      "step": 26
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.0833543539047241,
      "learning_rate": 0.00024599999999999996,
      "loss": 1.5689,
      "step": 27
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.1457244157791138,
      "learning_rate": 0.000244,
      "loss": 1.7405,
      "step": 28
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.896858274936676,
      "learning_rate": 0.00024199999999999997,
      "loss": 1.5509,
      "step": 29
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.9905090928077698,
      "learning_rate": 0.00023999999999999998,
      "loss": 1.5828,
      "step": 30
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.9686444401741028,
      "learning_rate": 0.00023799999999999998,
      "loss": 1.7112,
      "step": 31
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.1740665435791016,
      "learning_rate": 0.00023599999999999996,
      "loss": 1.5509,
      "step": 32
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.941399335861206,
      "learning_rate": 0.000234,
      "loss": 1.7395,
      "step": 33
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.1059672832489014,
      "learning_rate": 0.00023199999999999997,
      "loss": 1.4403,
      "step": 34
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.118407964706421,
      "learning_rate": 0.00023,
      "loss": 1.8212,
      "step": 35
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.9892570376396179,
      "learning_rate": 0.00022799999999999999,
      "loss": 1.573,
      "step": 36
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.0876305103302002,
      "learning_rate": 0.00022599999999999996,
      "loss": 1.4309,
      "step": 37
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.0983166694641113,
      "learning_rate": 0.000224,
      "loss": 1.516,
      "step": 38
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.0992014408111572,
      "learning_rate": 0.00022199999999999998,
      "loss": 1.5006,
      "step": 39
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.2225499153137207,
      "learning_rate": 0.00021999999999999995,
      "loss": 1.4841,
      "step": 40
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.3438453674316406,
      "learning_rate": 0.00021799999999999999,
      "loss": 1.6801,
      "step": 41
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.1127607822418213,
      "learning_rate": 0.00021599999999999996,
      "loss": 1.5554,
      "step": 42
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.6131433248519897,
      "learning_rate": 0.000214,
      "loss": 1.4885,
      "step": 43
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.138953685760498,
      "learning_rate": 0.00021199999999999998,
      "loss": 1.2026,
      "step": 44
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.2026135921478271,
      "learning_rate": 0.00020999999999999998,
      "loss": 1.2627,
      "step": 45
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.2164071798324585,
      "learning_rate": 0.000208,
      "loss": 1.7107,
      "step": 46
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.165000557899475,
      "learning_rate": 0.00020599999999999997,
      "loss": 1.4847,
      "step": 47
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.1352832317352295,
      "learning_rate": 0.000204,
      "loss": 1.7542,
      "step": 48
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.177304744720459,
      "learning_rate": 0.00020199999999999998,
      "loss": 1.5529,
      "step": 49
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.2504863739013672,
      "learning_rate": 0.00019999999999999998,
      "loss": 1.4412,
      "step": 50
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.9590234160423279,
      "learning_rate": 0.000198,
      "loss": 1.4152,
      "step": 51
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.2127907276153564,
      "learning_rate": 0.00019599999999999997,
      "loss": 1.1087,
      "step": 52
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.9996484518051147,
      "learning_rate": 0.00019399999999999997,
      "loss": 1.419,
      "step": 53
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.9060561656951904,
      "learning_rate": 0.00019199999999999998,
      "loss": 1.5145,
      "step": 54
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.0855937004089355,
      "learning_rate": 0.00018999999999999998,
      "loss": 1.3043,
      "step": 55
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.3786730766296387,
      "learning_rate": 0.000188,
      "loss": 1.3341,
      "step": 56
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 1.1414157152175903,
      "learning_rate": 0.000186,
      "loss": 1.3661,
      "step": 57
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.9981240630149841,
      "learning_rate": 0.00018399999999999997,
      "loss": 1.2821,
      "step": 58
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.4054723978042603,
      "learning_rate": 0.00018199999999999998,
      "loss": 1.5696,
      "step": 59
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.3735893964767456,
      "learning_rate": 0.00017999999999999998,
      "loss": 1.453,
      "step": 60
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.3395675420761108,
      "learning_rate": 0.000178,
      "loss": 1.3071,
      "step": 61
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.5593750476837158,
      "learning_rate": 0.000176,
      "loss": 1.6183,
      "step": 62
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.089756727218628,
      "learning_rate": 0.00017399999999999997,
      "loss": 1.3935,
      "step": 63
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.5685385465621948,
      "learning_rate": 0.000172,
      "loss": 1.3893,
      "step": 64
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.1929099559783936,
      "learning_rate": 0.00016999999999999999,
      "loss": 1.3507,
      "step": 65
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.151414394378662,
      "learning_rate": 0.000168,
      "loss": 1.4621,
      "step": 66
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.2570933103561401,
      "learning_rate": 0.000166,
      "loss": 1.5022,
      "step": 67
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 1.2988884449005127,
      "learning_rate": 0.00016399999999999997,
      "loss": 1.5503,
      "step": 68
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.2534974813461304,
      "learning_rate": 0.000162,
      "loss": 1.3052,
      "step": 69
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.453526496887207,
      "learning_rate": 0.00015999999999999999,
      "loss": 1.4542,
      "step": 70
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.0904637575149536,
      "learning_rate": 0.00015799999999999996,
      "loss": 1.3703,
      "step": 71
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.3031363487243652,
      "learning_rate": 0.000156,
      "loss": 1.5314,
      "step": 72
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.496485948562622,
      "learning_rate": 0.00015399999999999998,
      "loss": 1.6665,
      "step": 73
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.2557928562164307,
      "learning_rate": 0.000152,
      "loss": 1.4988,
      "step": 74
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.9684048891067505,
      "learning_rate": 0.00015,
      "loss": 1.3287,
      "step": 75
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.275840163230896,
      "learning_rate": 0.000148,
      "loss": 1.5077,
      "step": 76
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.4975206851959229,
      "learning_rate": 0.000146,
      "loss": 1.5965,
      "step": 77
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.6247934103012085,
      "learning_rate": 0.00014399999999999998,
      "loss": 1.2583,
      "step": 78
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.460990309715271,
      "learning_rate": 0.00014199999999999998,
      "loss": 1.3155,
      "step": 79
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.2134149074554443,
      "learning_rate": 0.00014,
      "loss": 1.3412,
      "step": 80
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.4794684648513794,
      "learning_rate": 0.000138,
      "loss": 1.476,
      "step": 81
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 1.5518884658813477,
      "learning_rate": 0.00013599999999999997,
      "loss": 1.4594,
      "step": 82
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 1.1933904886245728,
      "learning_rate": 0.00013399999999999998,
      "loss": 1.4483,
      "step": 83
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 1.451993465423584,
      "learning_rate": 0.00013199999999999998,
      "loss": 1.6392,
      "step": 84
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.469612956047058,
      "learning_rate": 0.00013,
      "loss": 1.2227,
      "step": 85
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.452088475227356,
      "learning_rate": 0.000128,
      "loss": 1.6058,
      "step": 86
    },
    {
      "epoch": 1.74,
      "grad_norm": 2.3288280963897705,
      "learning_rate": 0.00012599999999999997,
      "loss": 1.3481,
      "step": 87
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.9831671714782715,
      "learning_rate": 0.00012399999999999998,
      "loss": 1.2922,
      "step": 88
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.615618348121643,
      "learning_rate": 0.000122,
      "loss": 1.2652,
      "step": 89
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.972676157951355,
      "learning_rate": 0.00011999999999999999,
      "loss": 1.3942,
      "step": 90
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 1.5586673021316528,
      "learning_rate": 0.00011799999999999998,
      "loss": 1.5738,
      "step": 91
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 1.835627794265747,
      "learning_rate": 0.00011599999999999999,
      "loss": 1.502,
      "step": 92
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 1.697531819343567,
      "learning_rate": 0.00011399999999999999,
      "loss": 1.4524,
      "step": 93
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.4474732875823975,
      "learning_rate": 0.000112,
      "loss": 1.4563,
      "step": 94
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.6453442573547363,
      "learning_rate": 0.00010999999999999998,
      "loss": 1.291,
      "step": 95
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.4276905059814453,
      "learning_rate": 0.00010799999999999998,
      "loss": 1.2308,
      "step": 96
    },
    {
      "epoch": 1.94,
      "grad_norm": 1.3588879108428955,
      "learning_rate": 0.00010599999999999999,
      "loss": 1.2596,
      "step": 97
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.2365357875823975,
      "learning_rate": 0.000104,
      "loss": 1.1981,
      "step": 98
    },
    {
      "epoch": 1.98,
      "grad_norm": 1.6201108694076538,
      "learning_rate": 0.000102,
      "loss": 1.6398,
      "step": 99
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.6939184665679932,
      "learning_rate": 9.999999999999999e-05,
      "loss": 1.3389,
      "step": 100
    },
    {
      "epoch": 2.02,
      "grad_norm": 1.4354301691055298,
      "learning_rate": 9.799999999999998e-05,
      "loss": 1.368,
      "step": 101
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.5868160724639893,
      "learning_rate": 9.599999999999999e-05,
      "loss": 1.1337,
      "step": 102
    },
    {
      "epoch": 2.06,
      "grad_norm": 1.262750267982483,
      "learning_rate": 9.4e-05,
      "loss": 1.31,
      "step": 103
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.5369969606399536,
      "learning_rate": 9.199999999999999e-05,
      "loss": 1.3702,
      "step": 104
    },
    {
      "epoch": 2.1,
      "grad_norm": 1.5032826662063599,
      "learning_rate": 8.999999999999999e-05,
      "loss": 1.4036,
      "step": 105
    },
    {
      "epoch": 2.12,
      "grad_norm": 1.3789336681365967,
      "learning_rate": 8.8e-05,
      "loss": 1.2491,
      "step": 106
    },
    {
      "epoch": 2.14,
      "grad_norm": 1.403449296951294,
      "learning_rate": 8.6e-05,
      "loss": 1.2007,
      "step": 107
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.7922415733337402,
      "learning_rate": 8.4e-05,
      "loss": 1.4839,
      "step": 108
    },
    {
      "epoch": 2.18,
      "grad_norm": 1.5774747133255005,
      "learning_rate": 8.199999999999999e-05,
      "loss": 1.1137,
      "step": 109
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.3172965049743652,
      "learning_rate": 7.999999999999999e-05,
      "loss": 1.3035,
      "step": 110
    },
    {
      "epoch": 2.22,
      "grad_norm": 1.158752679824829,
      "learning_rate": 7.8e-05,
      "loss": 1.3143,
      "step": 111
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.5268526077270508,
      "learning_rate": 7.6e-05,
      "loss": 1.2566,
      "step": 112
    },
    {
      "epoch": 2.26,
      "grad_norm": 1.8207499980926514,
      "learning_rate": 7.4e-05,
      "loss": 1.2636,
      "step": 113
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 1.4870548248291016,
      "learning_rate": 7.199999999999999e-05,
      "loss": 1.2789,
      "step": 114
    },
    {
      "epoch": 2.3,
      "grad_norm": 1.335573434829712,
      "learning_rate": 7e-05,
      "loss": 1.2463,
      "step": 115
    },
    {
      "epoch": 2.32,
      "grad_norm": 1.9183930158615112,
      "learning_rate": 6.799999999999999e-05,
      "loss": 1.3521,
      "step": 116
    },
    {
      "epoch": 2.34,
      "grad_norm": 1.5728150606155396,
      "learning_rate": 6.599999999999999e-05,
      "loss": 1.4455,
      "step": 117
    },
    {
      "epoch": 2.36,
      "grad_norm": 1.5257213115692139,
      "learning_rate": 6.4e-05,
      "loss": 1.2196,
      "step": 118
    },
    {
      "epoch": 2.38,
      "grad_norm": 1.7710875272750854,
      "learning_rate": 6.199999999999999e-05,
      "loss": 1.4696,
      "step": 119
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.6722947359085083,
      "learning_rate": 5.9999999999999995e-05,
      "loss": 1.1961,
      "step": 120
    },
    {
      "epoch": 2.42,
      "grad_norm": 1.761246681213379,
      "learning_rate": 5.7999999999999994e-05,
      "loss": 1.4462,
      "step": 121
    },
    {
      "epoch": 2.44,
      "grad_norm": 1.6321829557418823,
      "learning_rate": 5.6e-05,
      "loss": 1.2955,
      "step": 122
    },
    {
      "epoch": 2.46,
      "grad_norm": 1.7694393396377563,
      "learning_rate": 5.399999999999999e-05,
      "loss": 1.444,
      "step": 123
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.36509370803833,
      "learning_rate": 5.2e-05,
      "loss": 1.2457,
      "step": 124
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.355251431465149,
      "learning_rate": 4.9999999999999996e-05,
      "loss": 1.2191,
      "step": 125
    },
    {
      "epoch": 2.52,
      "grad_norm": 1.7418643236160278,
      "learning_rate": 4.7999999999999994e-05,
      "loss": 1.5119,
      "step": 126
    },
    {
      "epoch": 2.54,
      "grad_norm": 1.9838306903839111,
      "learning_rate": 4.599999999999999e-05,
      "loss": 1.149,
      "step": 127
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.744920492172241,
      "learning_rate": 4.4e-05,
      "loss": 1.27,
      "step": 128
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.0769169330596924,
      "learning_rate": 4.2e-05,
      "loss": 1.2377,
      "step": 129
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.7754156589508057,
      "learning_rate": 3.9999999999999996e-05,
      "loss": 1.1746,
      "step": 130
    },
    {
      "epoch": 2.62,
      "grad_norm": 1.795027494430542,
      "learning_rate": 3.8e-05,
      "loss": 0.9615,
      "step": 131
    },
    {
      "epoch": 2.64,
      "grad_norm": 1.928368330001831,
      "learning_rate": 3.5999999999999994e-05,
      "loss": 1.225,
      "step": 132
    },
    {
      "epoch": 2.66,
      "grad_norm": 1.676374912261963,
      "learning_rate": 3.399999999999999e-05,
      "loss": 1.3029,
      "step": 133
    },
    {
      "epoch": 2.68,
      "grad_norm": 1.764739751815796,
      "learning_rate": 3.2e-05,
      "loss": 1.3958,
      "step": 134
    },
    {
      "epoch": 2.7,
      "grad_norm": 1.8606576919555664,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 1.5392,
      "step": 135
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 1.7965049743652344,
      "learning_rate": 2.8e-05,
      "loss": 1.3047,
      "step": 136
    },
    {
      "epoch": 2.74,
      "grad_norm": 1.5134313106536865,
      "learning_rate": 2.6e-05,
      "loss": 1.2114,
      "step": 137
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.0863735675811768,
      "learning_rate": 2.3999999999999997e-05,
      "loss": 1.2778,
      "step": 138
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 1.5968434810638428,
      "learning_rate": 2.2e-05,
      "loss": 1.3974,
      "step": 139
    },
    {
      "epoch": 2.8,
      "grad_norm": 2.3537583351135254,
      "learning_rate": 1.9999999999999998e-05,
      "loss": 1.2482,
      "step": 140
    },
    {
      "epoch": 2.82,
      "grad_norm": 1.7480820417404175,
      "learning_rate": 1.7999999999999997e-05,
      "loss": 1.42,
      "step": 141
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.9234390258789062,
      "learning_rate": 1.6e-05,
      "loss": 1.3265,
      "step": 142
    },
    {
      "epoch": 2.86,
      "grad_norm": 1.828490138053894,
      "learning_rate": 1.4e-05,
      "loss": 1.2908,
      "step": 143
    },
    {
      "epoch": 2.88,
      "grad_norm": 2.159350872039795,
      "learning_rate": 1.1999999999999999e-05,
      "loss": 1.1083,
      "step": 144
    },
    {
      "epoch": 2.9,
      "grad_norm": 1.5734061002731323,
      "learning_rate": 9.999999999999999e-06,
      "loss": 1.3504,
      "step": 145
    },
    {
      "epoch": 2.92,
      "grad_norm": 1.7648757696151733,
      "learning_rate": 8e-06,
      "loss": 1.329,
      "step": 146
    },
    {
      "epoch": 2.94,
      "grad_norm": 1.5285753011703491,
      "learning_rate": 5.999999999999999e-06,
      "loss": 1.3196,
      "step": 147
    },
    {
      "epoch": 2.96,
      "grad_norm": 1.5299556255340576,
      "learning_rate": 4e-06,
      "loss": 1.3406,
      "step": 148
    },
    {
      "epoch": 2.98,
      "grad_norm": 2.0067498683929443,
      "learning_rate": 2e-06,
      "loss": 1.5094,
      "step": 149
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.9711816310882568,
      "learning_rate": 0.0,
      "loss": 1.3367,
      "step": 150
    }
  ],
  "logging_steps": 1,
  "max_steps": 150,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1800936359395328e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
